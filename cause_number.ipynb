{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b151a316-2352-4b39-929a-178487802555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from PyPDF2 import PdfFileReader\n",
    "import docx2txt\n",
    "import openpyxl\n",
    "import gspread\n",
    "import df2gspread as d2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfa63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract pdf text\n",
    "file = open('pending_civil.pdf', 'rb') #opens pdf\n",
    "pdfReader = PdfFileReader(file) #reads pdf\n",
    "count = pdfReader.numPages #counts the number of pages\n",
    "content = \" \" #empty variable for the extracted text\n",
    "for i in range(count): #for loop to extract text from all pages\n",
    "    page = pdfReader.getPage(i) #gets page numbers\n",
    "    content += page.extractText() #extracts text from iterated pages\n",
    "    print(content)#, file = open('yesterdays_causes.txt', 'a')) #prints cause numbers to file. I did this because the extracted texts was seperated into lists by pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex - finds and extracts cause_numbers\n",
    "finds_cause_numbers = re.findall(r'\\d{2}-\\d{2}-\\d{5}-\\w*', content)#pattern for cause number\n",
    "#t_causenum is today's causenumber\n",
    "pending_cause_number_df = pd.DataFrame(finds_cause_numbers, columns = ['cause_number'])#puts the extract cause number into a df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353fc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pending_cause_number_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adce5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.service_account(filename = '/Users/hector/Desktop/pau/pending_cases.json')\n",
    "sht1 = gc.open_by_key('1b3fmZrbfwZWMvu4kUGJSSGsp61utlE0Ny-ebozZ5aBk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet = sht1.get_worksheet(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a800b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "civil_pending_notes = pd.DataFrame(worksheet.get_all_records())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#civil_pending_notes = pd.read_excel('civil_pending.xlsx')\n",
    "civil_pending_notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds both lists together in order to search for dups later\n",
    "df = civil_pending_notes.append(pd.DataFrame(pending_cause_number_df, columns=['cause_number']), ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7641ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops the duplicated cause numbers\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d04fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(' ')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet.update([df.columns.values.tolist()] + df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c33daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints to excel\n",
    "#add notes to this excel file\n",
    "df.to_excel('pending_cause_numbers.xlsx', sheet_name='pending_cause_numbers')  \n",
    "\n",
    "#New version of this will be a google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0dbe43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a595bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aaa616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1d3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dda7bc-4aff-4292-ac1a-2742c24cca58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#opens and reads the previous days pending report i.e. 'yesterdays_pending.pdf'\n",
    "file = open('yesterdays_pending.pdf', 'rb') #opens pdf\n",
    "pdfReader = PdfFileReader(file) #reads pdf\n",
    "count = pdfReader.numPages #counts the number of pages\n",
    "content = \" \"\n",
    "for i in range(count): #for loop to extract text from all pages\n",
    "    page = pdfReader.getPage(i) #gets page numbers\n",
    "    content += page.extractText() #extracts text from iterated pages\n",
    "    print(content)#, file = open('yesterdays_causes.txt', 'a')) #prints cause numbers to file. I did this because the extracted texts was seperated into lists by pages.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts cause numbers from the previous day's pending report\n",
    "y_causenum = re.findall(r'\\d{2}-\\d{2}-\\d{5}-\\w*', content)\n",
    "yesterday_df = pd.DataFrame(y_causenum, columns = ['cause_number'])#puts it into a df\n",
    "yesterday_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds both lists together in order to search for dups later\n",
    "df = todays_df.append(pd.DataFrame(y_causenum, columns=['cause_number']), ignore_index=True)\n",
    "df.shape #shape of total rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops the duplicated cause numbers\n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ecfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints to excel\n",
    "#add notes to this excel file\n",
    "df.to_excel('pending_causes.xlsx', sheet_name='pending_cause_numbers')  \n",
    "\n",
    "#New version of this will be a google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf98144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in the most recent excel file that has notes ie 'latest_df'\n",
    "latest_df = pd.read_excel('pending_causes.xlsx', index_col=0)#index_col = 0 so that it does not add in another indexed col\n",
    "#this will read in a google sheet that has the notes in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2badac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opens and reads the previous days pending report i.e. 'yesterdays_pending.pdf'\n",
    "file = open('7_pen.pdf', 'rb') #opens pdf\n",
    "pdfReader = PdfFileReader(file) #reads pdf\n",
    "count = pdfReader.numPages #counts the number of pages\n",
    "content = \" \"\n",
    "for i in range(count): #for loop to extract text from all pages\n",
    "    page = pdfReader.getPage(i) #gets page numbers\n",
    "    content += page.extractText() #extracts text from iterated pages\n",
    "    print(content)#, file = open('yesterdays_causes.txt', 'a')) #prints cause numbers to file. I did this because the extracted texts was seperated into lists by pages.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts new day report cause numbers to be compared to latest report\n",
    "t_causenum = re.findall(r'\\d{2}-\\d{2}-\\d{5}-\\w*', content)\n",
    "todays_df = pd.DataFrame(t_causenum, columns = ['cause_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9dc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes the new day report and adds it to the latest report for comparison\n",
    "df = latest_df.append(pd.DataFrame(todays_df, columns=['cause_number']), ignore_index=True) #adds both lists together in order to search for dups later\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c04c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops the duplicated cause numbers\n",
    "df = df.drop_duplicates() \n",
    "df\n",
    "###Needs to be reindexes!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints back to excel\n",
    "#update this file\n",
    "df.to_excel(\"_pending_causes.xlsx\", sheet_name='pending_cause_numbers')  \n",
    "\n",
    "#New version of this will go back to the google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b5459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55179e-8a07-4055-b9ce-84cc640c859e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#duplicated=df[df.duplicated()] #finds all duplicates\n",
    "#duplicated.shape #count of rows and columns of the duplicated cause numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows ONLY the duplicates\n",
    "#duplicated.sort_values('cause_number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
